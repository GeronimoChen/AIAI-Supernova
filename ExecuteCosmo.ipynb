{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosmology\n",
    "Here are how to use the MRNN to do some cosmological predictions. To specify, the intrinsic luminosity of SNe.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import yaml\n",
    "import keras\n",
    "import astropy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras.backend as K\n",
    "import astropy.units as u\n",
    "import astropy.constants as c\n",
    "from astropy.time import Time\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "from keras.models import Sequential,Model\n",
    "from dust_extinction.averages import GCC09_MWAvg\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dust_extinction.parameter_averages import CCM89,F99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The B-band Magnitude Measure\n",
    "I got a rough B-band transmission, hope it is accurate enough.  \n",
    "And when you are using this B-band calculator, please check the wavelength sampling. In our spectra which has 2000 pixels between 2000 and 10000 Angstrom wavelength, the delta frequency is the default number.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BFilterMagCalculator(spec,delta_frequency=5.9958492*10**11*u.Hz):\n",
    "    #shortwave=2000\n",
    "    #longwave=10000\n",
    "    spec=pd.DataFrame(spec,columns=['wave','flux'])\n",
    "    #flux=spec[spec['wave']>shortwave]\n",
    "    #flux=flux[flux['wave']<longwave]\n",
    "    wave=np.array(spec['wave'])\n",
    "    flux=np.array(spec['flux'])\n",
    "    Bfilter=np.array([0.0,0.0,0.030,0.134,0.567,\n",
    "                      0.920,0.978,1.000,0.978,\n",
    "                      0.935,0.853,0.740,0.640,\n",
    "                      0.536,0.424,0.325,0.235,\n",
    "                      0.150,0.095,0.043,0.009,0.0,0.0])\n",
    "    Bwave=np.array([2000,3600,3700,3800,3900,\n",
    "                    4000,4100,4200,4300,\n",
    "                    4400,4500,4600,4700,\n",
    "                    4800,4900,5000,5100,\n",
    "                    5200,5300,5400,5500,5600,10000])\n",
    "    Bfunc=interp1d(Bwave,Bfilter)#The Johnson B filter\n",
    "    flux=flux*Bfunc(wave)\n",
    "    flux=flux/(1.1964952*10**40)#The spherical luminosity to the flux in a square centimeter at 10 parsec away. \n",
    "    delta_lambda=(wave*u.AA)**2*delta_frequency/c.c\n",
    "    delta_lambda=delta_lambda.to(unit=u.AA)\n",
    "    flux=sum(flux*delta_lambda.value)\n",
    "    #print(flux*(1.1964952*10**40))\n",
    "    #print(flux)\n",
    "    mag=-2.5*np.log10(flux/6.00069/10**-6)+0.03# Here it is the flux divided by Vega's apparent flux in B band by HST STIS measurement. \n",
    "    return mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalizer(spec,shortwave=6500,longwave=7500):\n",
    "    small=np.argmin(abs(spec[:,0]-shortwave))\n",
    "    long=np.argmin(abs(spec[:,0]-longwave))\n",
    "    if small<long:spec[:,1]=spec[:,1]/np.average(spec[small:long,1])\n",
    "    if small>long:spec[:,1]=spec[:,1]/np.average(spec[long:small,1])\n",
    "    return spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Flux\n",
    "And also calculate the b band absolute magnitude, then normalize the spectra. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.load('DataSet/X.npy')\n",
    "Y=np.zeros(X.shape[0])\n",
    "wave=np.load('DataSet/wave.npy')\n",
    "for i in range(X.shape[0]):\n",
    "    bmag=BFilterMagCalculator(np.array([wave,X[i].flatten()]).T)\n",
    "    if bmag>-17.5:continue\n",
    "    spdata=np.array([wave,X[i]]).T\n",
    "    spdata=Normalizer(spdata)\n",
    "    if np.max(spdata[:,1])>30:continue\n",
    "    Y[i]=bmag\n",
    "X=X/np.average(X[:,167:269])\n",
    "magaver=-19\n",
    "magstd=1\n",
    "Y=Y-magaver/magstd\n",
    "Y=np.tanh(Y)/2+0.5\n",
    "Y=pd.DataFrame(Y,columns=[str(i)+'_'+str(j) for i in range(6,29) for j in range(1,5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data part 2\n",
    "This part is the original part to read the data into the python program.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "for i in [1,2,3,4,5,6,7,8,9,13,14,15,16,17,18,19,20,21]:\n",
    "    data.append(pd.read_csv('csvs/'+str(i)+'.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specdirs=['Spec/'+str(i)+'/*' for i in [1,2,3,4,5,6,7,8,9,13,14,15,16,17,18,19,20,21]]\n",
    "specs=[]\n",
    "speccounts=[]\n",
    "for i in specdirs:\n",
    "    specsmall=[]\n",
    "    speccountsmall=[]\n",
    "    for j in glob.glob(i):\n",
    "        #if int(j.split('/')[2].split('.txt')[0])\n",
    "        k=np.genfromtxt(j)\n",
    "        specsmall.append(k)\n",
    "        speccountsmall.append(int(j.split('/')[2].split('.txt')[0]))\n",
    "    print(i)\n",
    "    specs.append(specsmall)\n",
    "    speccounts.append(speccountsmall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "Y=[]\n",
    "Mags=[]\n",
    "for i in range(len(specs)):\n",
    "    for j in range(len(specs[i])):\n",
    "        spdata=specs[i][j]\n",
    "        bmag=BFilterMagCalculator(spdata).copy()\n",
    "        if bmag>-17.5:continue\n",
    "        spdata=Normalizer(spdata)\n",
    "        if np.max(spdata[:,1])>30:continue\n",
    "        Mags.append(bmag)\n",
    "        X.append(spdata[:,1])\n",
    "        Y.append(np.array(data[i].iloc[speccounts[i][j],3:]))\n",
    "X=np.array(X)\n",
    "X=X.reshape(X.shape[0],2000,1)\n",
    "Y=np.array(Y)\n",
    "Y=pd.DataFrame(Y,columns=['mag'])\n",
    "Y=(Y-Yaverage)/Ystd\n",
    "Y=np.tanh(Y)/2+0.5\n",
    "Y=pd.DataFrame(Y,columns=[str(i)+'_'+str(j) for i in range(6,29) for j in range(1,5)])\n",
    "Mags=np.array(Mags)\n",
    "\n",
    "magaver=-19\n",
    "magstd=1\n",
    "\n",
    "Ymag=np.tanh((Mags-magaver)/magstd)/2+0.5\n",
    "Ymag=pd.DataFrame({'mag':Ymag})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataAugmenter(Xoriginal,Yoriginal):\n",
    "    noisparam1=50\n",
    "    noisparam2=5\n",
    "    X2=Xoriginal\n",
    "    Y2=Yoriginal\n",
    "    X3=Xoriginal\n",
    "    F5500=X3[:,400:420].mean(axis=1)\n",
    "    F5500=F5500.reshape([X3.shape[0],1,1])\n",
    "    Slist=np.random.random(X3.shape[0])*noisparam1+noisparam2# you can modify the 50 and 5 here depending how much noise you want to add\n",
    "    Slist=Slist.reshape([X3.shape[0],1,1])\n",
    "    Noiselist=np.random.randn(X3.shape[0]*X3.shape[1]).reshape([X3.shape[0],X3.shape[1],1])*X3**0.5\n",
    "    X3=X3*(1+Noiselist/F5500**0.5/Slist)\n",
    "    Y3=Yoriginal\n",
    "    for i in range(len(X2)):\n",
    "        X2[i]=savgol_filter(X2[i].T,\\\n",
    "                                  np.random.choice([7,9,11,13,15,17,19,21,23,25]),\\\n",
    "                                  np.random.choice([2,3,4,5,6])).T\n",
    "    Xaugment=np.concatenate([Xoriginal,X2,X3])\n",
    "    Yaugment=pd.concat([Yoriginal,Y2,Y3])\n",
    "    return Xaugment,Yaugment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,train_size=0.9)\n",
    "X_train,Y_train=DataAugmenter(X_train,Y_train)\n",
    "X_train,Y_train=DataAugmenter(X_train,Y_train)\n",
    "\n",
    "X_test2,Y_test2=DataAugmenter(X_test,Y_test)\n",
    "X_test3,Y_test3=DataAugmenter(X_test2,Y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UltraDenseResNeuro(NameShell='26_3',CellNumber=7,\\\n",
    "                       X_train=X_train,X_test=X_test,Y_train=Y_train,Y_test=Y_test,usegpu=True):\n",
    "    INput=Input(shape=(X_train.shape[1],1,))\n",
    "    conv1=Conv1D(8,15,strides=2,padding='same')(INput)\n",
    "    conv1=Conv1D(16,3,strides=1,padding='same')(conv1)\n",
    "    batc1=BatchNormalization()(conv1)\n",
    "    acti1=Activation('relu')(batc1)\n",
    "    pool1=MaxPooling1D(2)(acti1)\n",
    "    \n",
    "    conv2=Conv1D(8,1)(pool1)\n",
    "    batc2=BatchNormalization()(conv2)\n",
    "    acti2=Activation('relu')(batc2)\n",
    "    conv3=Conv1D(16,3,padding='same')(acti2)\n",
    "    \n",
    "    add1=Add()([pool1,conv3])\n",
    "    \n",
    "    conv2=Conv1D(8,1)(add1)\n",
    "    batc2=BatchNormalization()(conv2)\n",
    "    acti2=Activation('relu')(batc2)\n",
    "    conv3=Conv1D(16,3,padding='same')(acti2)\n",
    "    \n",
    "    adds=[add1]\n",
    "    addi=Add()(adds+[conv3])\n",
    "    adds.append(addi)\n",
    "    \n",
    "    for i in range(CellNumber):\n",
    "        conv2=Conv1D(8,1)(addi)\n",
    "        batc2=BatchNormalization()(conv2)\n",
    "        acti2=Activation('relu')(batc2)\n",
    "        conv3=Conv1D(16,3,padding='same')(acti2)\n",
    "        addi=Add()(adds+[conv3])\n",
    "        adds.append(addi)\n",
    "    \n",
    "    batc2=BatchNormalization()(addi)\n",
    "    flat1=keras.layers.Flatten()(batc2)\n",
    "    drop1=Dropout(0.2)(flat1)\n",
    "    dens1=Dense(256,activation='relu')(drop1)\n",
    "    drop2=Dropout(0.2)(dens1)\n",
    "    dens2=Dense(128,activation='relu')(drop2)\n",
    "    dens3=Dense(1,activation='sigmoid')(dens2)\n",
    "    \n",
    "    model=Model(inputs=INput,outputs=dens3)\n",
    "    print(model.summary())\n",
    "    if usegpu==True:model=keras.utils.multi_gpu_model(model,gpus=2)\n",
    "    opt=keras.optimizers.adam(lr=0.000003,decay=1e-6)\n",
    "    model.compile(optimizer=opt,loss='mse')    \n",
    "    history1=model.fit(X_train,Y_train[NameShell],epochs=700,\\\n",
    "              validation_data=[X_test,Y_test[NameShell]],batch_size=4000,\\\n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=1)],verbose=1)\n",
    "    opt=keras.optimizers.adam(lr=0.00000003,decay=1e-6)\n",
    "    model.compile(optimizer=opt,loss='mse')\n",
    "    history2=model.fit(X_train,Y_train[NameShell],epochs=700,\\\n",
    "              validation_data=[X_test,Y_test[NameShell]],batch_size=10000,\\\n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=1)],verbose=1)\n",
    "    return model,history1,history2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run it many times\n",
    "Because this neural network is not that stable on the luminosity dataset, I tried to run the prediction model several times, and store the best one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,his1,his2=UltraDenseResNeuro(NameShell='mag',usegpu=True)\n",
    "memory=his2.history['val_loss'][0]\n",
    "while True:\n",
    "    model,his1,his2=UltraDenseResNeuro(NameShell='mag',usegpu=True)\n",
    "    if his2.history['val_loss'][0]<memory:\n",
    "        memory=his2.history['val_loss'][0]\n",
    "        model.save('MdSaver/Cosmo/Naive'+str(round(memory,9))+'.hdf')\n",
    "        Yout=model.predict(X_test,batch_size=2000)\n",
    "        np.save('DataCache/Cosmo/YoutNaive'+str(round(memory,9))+'.npy',Yout)\n",
    "        np.save('DataCache/Cosmo/XtestNaive.npy',X_test)\n",
    "        Y_test.to_csv('DataCache/Cosmo/YtestNaive.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BMagPred(spectra,z):\n",
    "    mag=np.arctanh(2*(Predictor(model,spectra,z)[0][0]-0.5))*magstd+magaver\n",
    "    return mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectralist=[\n",
    "    'ObserveSpectra/Prediction/SN2011fe/SN2011fe_0.4d.dat',\n",
    "    'ObserveSpectra/Prediction/SN2011fe/SN2011fe_-2.6d.dat',\n",
    "    'ObserveSpectra/Prediction/SN2011fe/SN2011fe_3.7d.dat',\n",
    "    'ObserveSpectra/Prediction/SN2013dy/SN2013dy_-3.1d.flm',\n",
    "    'ObserveSpectra/Prediction/SN2013dy/SN2013dy_-1.1d.flm',\n",
    "    'ObserveSpectra/Prediction/SN2013dy/SN2013dy_0.9d.flm',\n",
    "    'ObserveSpectra/Prediction/SN2013dy/SN2013dy_3.9d.flm',\n",
    "    'ObserveSpectra/Prediction/SN2011iv/SN2011iv_0.6d.flm',\n",
    "    'ObserveSpectra/Prediction/SN2015F/SN2015F_-2.3d.flm',\n",
    "    'ObserveSpectra/Prediction/ASASSN-14lp/ASASSN-14lp_-4.4d.flm',\n",
    "    'ObserveSpectra/Prediction/SN2011by/SN2011by_-0.4d.flm']\n",
    "ext1list=[CCM89(Rv=3.1),CCM89(Rv=3.1),CCM89(Rv=3.1),\n",
    "         CCM89(Rv=3.1),CCM89(Rv=3.1),CCM89(Rv=3.1),CCM89(Rv=3.1),\n",
    "         CCM89(Rv=3.1),CCM89(Rv=3.1),CCM89(Rv=3.1),F99(Rv=3.1)]\n",
    "ext2list=[GCC09_MWAvg(),GCC09_MWAvg(),GCC09_MWAvg(),\n",
    "         GCC09_MWAvg(),GCC09_MWAvg(),GCC09_MWAvg(),GCC09_MWAvg(),\n",
    "         GCC09_MWAvg(),GCC09_MWAvg(),GCC09_MWAvg(),GCC09_MWAvg()]\n",
    "ext1EbvList=[0,0,0,0.206,0.206,0.206,0.206,0,0.035,0.33,0.039]\n",
    "ext2EbvList=[0,0,0,0.135,0.135,0.135,0.135,0,0.175,0.021,0.013]\n",
    "zlist=[0.000804,0.000804,0.000804,0.00389,0.00389,0.00389,0.00389,0.006494,0.0049,0.0051,0.002843]\n",
    "snname=['SN2011fe_0.4d','SN2011fe_-2.6d','SN2011fe_3.7d','SN2013dy_-3.1d','SN2013dy_-1.1d',\n",
    "        'SN2013dy_0.9d','SN2013dy_3.9d','SN2011iv_0.6d','SN2015F_-2.3d','ASASSN-14lp_-4.4d','SN2011by_-0.4d']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Prediction\n",
    "I write the prediction functions here, the best model I have and its relating testing dataset are also shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yout=np.load('DataCache/Cosmo/Yout2018.3.10.000432561.npy')\n",
    "Yreal=pd.read_csv('DataCache/Cosmo/Ytest2018.3.1.csv')\n",
    "model=keras.models.load_model('MdSaver/Cosmo/Aver-19_Std1_NBF_2018.3.10.000432561.hdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ObserveYoutData=[]\n",
    "for i in range(11):\n",
    "    spr=np.genfromtxt(spectralist[i])\n",
    "    ObserveYoutData.append(NewPredictor(spr,ext1list[i],ext2list[i],ext1EbvList[i],ext2EbvList[i],zlist[i]))\n",
    "ObserveYoutData=np.array(ObserveYoutData).flatten()\n",
    "for i in range(len(ObserveYoutData)):\n",
    "    predmag=np.arctanh(2*(ObserveYoutData[i]-0.5))*magstd+magaver    \n",
    "    lower,upper=OneSigmaCalculator(Yout,Yreal['mag'],center=ObserveYoutData[i])\n",
    "    middle=MiddleCalculator(Yout,Yreal['mag'],center=ObserveYoutData[i])\n",
    "    lowmag=np.arctanh(2*(lower-0.5))*magstd+magaver\n",
    "    uppmag=np.arctanh(2*(upper-0.5))*magstd+magaver\n",
    "    midmag=np.arctanh(2*(middle-0.5))*magstd+magaver\n",
    "    print(snname[i],lowmag,midmag,predmag,uppmag)\n",
    "    print(lowmag-midmag,uppmag-midmag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:keras]",
   "language": "python",
   "name": "conda-env-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
