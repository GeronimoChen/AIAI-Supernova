{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Predictions\n",
    "I prepared a special method to predict the element abundances here, primarily due to the poorly optimized keras package.  \n",
    "The problem is that (especially when you are using keras-gpu in jupyter notebook) loading a model into memory usually takes some time, but only a few computer resource is used. So, I write another script to store all the codes necessarily for the deep learning prediction, and load the trained model, and run many python programs simultaneously.  \n",
    "Also, the GPU acceeration here is not useful, because the time is limited by I/O rather than calculation and GPUs are not always have more memory than RAM. \n",
    "So I specify CPU for this task. \n",
    "Be careful, it may cause a drastic increase in CPU load and RAM memory for a few seconds.  \n",
    "\n",
    "Firstly, you need to check the existence of spectra. Also, the redshift and the extinctions shall be specified.  \n",
    "Here I list the 11 HST spectra used in my paper.  \n",
    "Moreover, you can choose some SN names here, and you can find the TARDIS readable element abundances with the as-chosen names in a directory (which will be specified later).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import yaml\n",
    "import keras\n",
    "import astropy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras.backend as K\n",
    "import astropy.units as u\n",
    "import astropy.constants as c\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "from keras.models import Sequential,Model\n",
    "from dust_extinction.averages import GCC09_MWAvg\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dust_extinction.parameter_averages import CCM89,F99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProberRes=pd.read_csv('MdSaver/SmallRun/DataRes.csv')\n",
    "RawElems=[str(i)+'_'+str(j) for i in range(6,29) for j in [1,2,3,4]]\n",
    "ChosenElem=[]\n",
    "for k in RawElems:\n",
    "    if ProberRes[k][0]>0.1:continue\n",
    "    ChosenElem.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectralist=[\n",
    "    'ObserveSpectra/Prediction/SN2011fe/SN2011fe_0.4d.dat',\n",
    "    'ObserveSpectra/Prediction/SN2011fe/SN2011fe_-2.6d.dat',\n",
    "    'ObserveSpectra/Prediction/SN2011fe/SN2011fe_3.7d.dat',\n",
    "    'ObserveSpectra/Prediction/SN2013dy/SN2013dy_-3.1d.flm',\n",
    "    'ObserveSpectra/Prediction/SN2013dy/SN2013dy_-1.1d.flm',\n",
    "    'ObserveSpectra/Prediction/SN2013dy/SN2013dy_0.9d.flm',\n",
    "    'ObserveSpectra/Prediction/SN2013dy/SN2013dy_3.9d.flm',\n",
    "    'ObserveSpectra/Prediction/SN2011iv/SN2011iv_0.6d.flm',\n",
    "    'ObserveSpectra/Prediction/SN2015F/SN2015F_-2.3d.flm',\n",
    "    'ObserveSpectra/Prediction/ASASSN-14lp/ASASSN-14lp_-4.4d.flm',\n",
    "    'ObserveSpectra/Prediction/SN2011by/SN2011by_-0.4d.flm']\n",
    "ext1list=[CCM89(Rv=3.1),CCM89(Rv=3.1),CCM89(Rv=3.1),\n",
    "         CCM89(Rv=3.1),CCM89(Rv=3.1),CCM89(Rv=3.1),CCM89(Rv=3.1),\n",
    "         CCM89(Rv=3.1),CCM89(Rv=3.1),CCM89(Rv=3.1),F99(Rv=3.1)]\n",
    "ext2list=[GCC09_MWAvg(),GCC09_MWAvg(),GCC09_MWAvg(),\n",
    "         GCC09_MWAvg(),GCC09_MWAvg(),GCC09_MWAvg(),GCC09_MWAvg(),\n",
    "         GCC09_MWAvg(),GCC09_MWAvg(),GCC09_MWAvg(),GCC09_MWAvg()]\n",
    "ext1EbvList=[0,0,0,0.206,0.206,0.206,0.206,0,0.035,0.33,0.039]\n",
    "ext2EbvList=[0,0,0,0.135,0.135,0.135,0.135,0,0.175,0.021,0.013]\n",
    "zlist=[0.000804,0.000804,0.000804,0.00389,0.00389,0.00389,0.00389,0.006494,0.0049,0.0051,0.002843]\n",
    "snname=['SN2011fe_0.4d','SN2011fe_-2.6d','SN2011fe_3.7d','SN2013dy_-3.1d','SN2013dy_-1.1d',\n",
    "        'SN2013dy_0.9d','SN2013dy_3.9d','SN2011iv_0.6d','SN2015F_-2.3d','ASASSN-14lp_-4.4d','SN2011by_-0.4d']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The environment\n",
    "You may need to set the python environment, make sure it won't detect the GPU card, then run on CPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['LD_LIBRARY_PATH']='/home/hulei/anaconda3/pkgs/cudatoolkit-9.2-0/lib'\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep On\n",
    "The next step is a little bit stupid, you need to copy the lists in the above cell and write them into a string form manually.  \n",
    "Then, run the cell and insert the observed spectra informations into the python script.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ObservedSpectralInformation='''\n",
    "spectralist=[\n",
    "    'ObserveSpectra/Prediction/SN2011fe/SN2011fe_0.4d.dat',\n",
    "    'ObserveSpectra/Prediction/SN2011fe/SN2011fe_-2.6d.dat',\n",
    "    'ObserveSpectra/Prediction/SN2011fe/SN2011fe_3.7d.dat',\n",
    "    'ObserveSpectra/Prediction/SN2013dy/SN2013dy_-3.1d.flm',\n",
    "    'ObserveSpectra/Prediction/SN2013dy/SN2013dy_-1.1d.flm',\n",
    "    'ObserveSpectra/Prediction/SN2013dy/SN2013dy_0.9d.flm',\n",
    "    'ObserveSpectra/Prediction/SN2013dy/SN2013dy_3.9d.flm',\n",
    "    'ObserveSpectra/Prediction/SN2011iv/SN2011iv_0.6d.flm',\n",
    "    'ObserveSpectra/Prediction/SN2015F/SN2015F_-2.3d.flm',\n",
    "    'ObserveSpectra/Prediction/ASASSN-14lp/ASASSN-14lp_-4.4d.flm',\n",
    "    'ObserveSpectra/Prediction/SN2011by/SN2011by_-0.4d.flm']\n",
    "ext1list=[CCM89(Rv=3.1),CCM89(Rv=3.1),CCM89(Rv=3.1),\n",
    "         CCM89(Rv=3.1),CCM89(Rv=3.1),CCM89(Rv=3.1),CCM89(Rv=3.1),\n",
    "         CCM89(Rv=3.1),CCM89(Rv=3.1),CCM89(Rv=3.1),F99(Rv=3.1)]\n",
    "ext2list=[GCC09_MWAvg(),GCC09_MWAvg(),GCC09_MWAvg(),\n",
    "         GCC09_MWAvg(),GCC09_MWAvg(),GCC09_MWAvg(),GCC09_MWAvg(),\n",
    "         GCC09_MWAvg(),GCC09_MWAvg(),GCC09_MWAvg(),GCC09_MWAvg()]\n",
    "ext1EbvList=[0,0,0,0.206,0.206,0.206,0.206,0,0.035,0.33,0.039]\n",
    "ext2EbvList=[0,0,0,0.135,0.135,0.135,0.135,0,0.175,0.021,0.013]\n",
    "zlist=[0.000804,0.000804,0.000804,0.00389,0.00389,0.00389,0.00389,0.006494,0.0049,0.0051,0.002843]\n",
    "snname=['SN2011fe_0.4d','SN2011fe_-2.6d','SN2011fe_3.7d','SN2013dy_-3.1d','SN2013dy_-1.1d',\n",
    "        'SN2013dy_0.9d','SN2013dy_3.9d','SN2011iv_0.6d','SN2015F_-2.3d','ASASSN-14lp_-4.4d','SN2011by_-0.4d']\n",
    "'''\n",
    "EnvironmentSpecifier='''\n",
    "os.environ['LD_LIBRARY_PATH']='/home/hulei/anaconda3/pkgs/cudatoolkit-9.2-0/lib'\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=''\n",
    "'''\n",
    "with open('PredictorOneElem.py','r') as scripter:\n",
    "    ScriptProgram=scripter.read()\n",
    "ScriptProgram=ScriptProgram.replace('######HereItIsTheSpecifier######',ObservedSpectralInformation)\n",
    "ScriptProgram=ScriptProgram.replace('######TheEnvironmentSpecifier######',ObservedSpectralInformation)\n",
    "with open('PredictorOneElemReallyRunner.py','w') as writter:\n",
    "    writter.write(ScriptProgram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let the Prediction Begin\n",
    "As I am using \"nohup\" here, don't expect the results are available soon after the notebook finished its calculation.  \n",
    "Here, you can specify the directory where the trained models are stored in \"modelposition\",  \n",
    "and specify the directory where the testing set spectra is stored in \"Xtextposition\",  \n",
    "and specify the directory where the testing set element abundance is stored in \"Ytestposition\",  \n",
    "and specify the output element abundance at \"observeoutposition\".  \n",
    "As before, you probably need to specify the conda environment, which is \"GeronimoEstellarChen\" here --apparently, you don't have my environment.  \n",
    "\n",
    "On my workstation with 384 GB RAM and 48 cores, it takes about a minute that you can do nothing but staring the htop which shows full-load.  \n",
    "If your computer is uncomfortable, you can set a timer here.  import time;time.sleep(10). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in ChosenElem:\n",
    "    modelposition='MdSaver/HunKRun/'+k+'.hdf'\n",
    "    Xtestposition='DataCache/2019.3.3/Xtest.npy'\n",
    "    Youtposition='DataCache/2019.3.3/Yout'+k+'.npy'\n",
    "    observeoutposition='DataCache/2019.3.3/ObsYout/'+k+'.npy'\n",
    "    os.popen('source activate GeronimoEstellarChen \\n'+\n",
    "             'nohup python PredictorOneElemReallyRunner.py '+modelposition+' '+Xtestposition+' '+Youtposition+' '+observeoutposition+' > /dev/null &')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Results\n",
    "Firstly, we shall read the results from the output files of the last cell, the \"datareader\" here matches the \"observeoutposition\" before.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PredData=pd.DataFrame(np.zeros([11,35]),columns=['NameList']+ChosenElem)\n",
    "PredData['NameList']=snname\n",
    "for k in ChosenElem:\n",
    "    datareader=np.load('DataCache/2019.3.3/ObsYout/'+k+'.npy')\n",
    "    datareader=datareader.reshape(11)\n",
    "    PredData[k]=datareader\n",
    "Y_test=pd.read_csv('DataCache/2019.3.3/Ytest.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Reverse and One-Sigma Limit\n",
    "In the Reverser function, the output of neural network (ranging from 0 to 1) were remapped to the original multiplicaiton factor (ranging from 0 to 3).  \n",
    "In the One-Sigma function, the 15th and 85th percentile of the testing dataset are calculated, we assume for a certain predicted value, its possible relating real value observes a normal distribution, then we calculate the one-sigma error like this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yaverage=np.array([1.49088116, 1.49097508, 1.50731088, 1.50455924, 1.51035671,\n",
    "       1.50782288, 1.51765324, 1.49176123, 1.49786083, 1.49164187,\n",
    "       1.51008039, 1.50649329, 1.49706889, 1.48256907, 1.50291872,\n",
    "       1.49671495, 1.48266993, 1.49328473, 1.49776985, 1.48788236,\n",
    "       1.50800197, 1.49640525, 1.49671263, 1.48329884, 1.50654272,\n",
    "       1.51546595, 1.50350355, 1.51359888, 1.50366677, 1.51347009,\n",
    "       1.49226848, 1.49165777, 1.49447523, 1.50564056, 1.50430572,\n",
    "       1.4965303 , 1.48774539, 1.50293614, 1.50234283, 1.49455285,\n",
    "       1.49912642, 1.49035065, 1.49374915, 1.48790414, 1.49469701,\n",
    "       1.51057406, 1.49123219, 1.49597135, 1.50784911, 1.49772004,\n",
    "       1.5341486 , 1.5098752 , 1.5031406 , 1.48253015, 1.48185943,\n",
    "       1.5142945 , 1.51335541, 1.49587574, 1.5064204 , 1.4859998 ,\n",
    "       1.49735422, 1.49443917, 1.49713147, 1.50904882, 1.50430961,\n",
    "       1.48899186, 1.4843948 , 1.50350289, 1.51124936, 1.50585086,\n",
    "       1.51427044, 1.49639282, 1.50156886, 1.50700966, 1.49711655,\n",
    "       1.50462769, 1.48889458, 1.50254653, 1.48807825, 1.49757542,\n",
    "       1.20827367, 1.48634746, 1.49944391, 1.51260678, 1.19763427,\n",
    "       1.51552949, 1.50722289, 1.49200582, 1.20885273, 1.48434282,\n",
    "       1.49319914, 1.49298437])\n",
    "Ystd=np.array([0.85998959, 0.86814719, 0.8687621 , 0.87050864, 0.86075304,\n",
    "       0.86440532, 0.86272026, 0.86967863, 0.8626639 , 0.86734201,\n",
    "       0.86057179, 0.87010535, 0.87411794, 0.8643628 , 0.86209518,\n",
    "       0.86797349, 0.86725306, 0.85800528, 0.86381744, 0.86611775,\n",
    "       0.8669094 , 0.86762243, 0.8675576 , 0.86361385, 0.86510062,\n",
    "       0.8652972 , 0.86980369, 0.86254431, 0.87056344, 0.86437873,\n",
    "       0.86389094, 0.87339658, 0.86688045, 0.86508027, 0.87134972,\n",
    "       0.86946127, 0.86630519, 0.8612666 , 0.86535052, 0.86876499,\n",
    "       0.85862661, 0.8706371 , 0.86687728, 0.86952742, 0.8607824 ,\n",
    "       0.86498409, 0.85954263, 0.85826469, 0.86454108, 0.86876391,\n",
    "       0.86799523, 0.86188565, 0.86329134, 0.86601738, 0.87293888,\n",
    "       0.86968641, 0.86252809, 0.87444087, 0.86285946, 0.8640128 ,\n",
    "       0.86677515, 0.87035309, 0.86068416, 0.86235551, 0.86720743,\n",
    "       0.86189559, 0.86178644, 0.86734348, 0.86053826, 0.86848727,\n",
    "       0.87080408, 0.86002404, 0.86218669, 0.85973503, 0.85875187,\n",
    "       0.87255914, 0.86074365, 0.86338974, 0.85837912, 0.86682464,\n",
    "       0.73932632, 0.85765432, 0.86773346, 0.87239269, 0.73557205,\n",
    "       0.86274201, 0.87080225, 0.86799464, 0.73390453, 0.86346123,\n",
    "       0.87181945, 0.87096847])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Reverser(Yout,elem='26_4'):\n",
    "    order=int(elem.split('_')[0])*4+int(elem.split('_')[1])-25\n",
    "    Yraw=np.arctanh(Yout*2-1)*Ystd[order]+Yaverage[order]\n",
    "    return Yraw\n",
    "def OneSigmaCalculator(Yout,Yreal,center=0.5,window=0.05):\n",
    "    Ylist=pd.DataFrame(np.array([Yout[:,0],np.array(Yreal)]).T,columns=['Yout','Yreal'])\n",
    "    Yselect=Ylist[(Ylist['Yout']>center-window) & (Ylist['Yout']<center+window)].copy()\n",
    "    if Yselect.shape[0]==0:\n",
    "        OneMinusSigma=0\n",
    "        MidData=0.5\n",
    "        OnePlusSigma=1\n",
    "    else:\n",
    "        OneMinusSigma=np.percentile(Yselect['Yreal'],15.865,axis=0)\n",
    "        MidData=np.percentile(Yselect['Yreal'],50,axis=0)\n",
    "        OnePlusSigma=np.percentile(Yselect['Yreal'],84.135,axis=0)\n",
    "    return OneMinusSigma,MidData,OnePlusSigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the Lower Limit and Upper Limit\n",
    "Here it is the one-sigma lower limit and the upper limit of all elements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "PredUpper=pd.DataFrame(np.zeros([11,35]),columns=['NameList']+ChosenElem)\n",
    "PredUpper['NameList']=snname\n",
    "PredMid=pd.DataFrame(np.zeros([11,35]),columns=['NameList']+ChosenElem)\n",
    "PredMid['NameList']=snname\n",
    "PredLower=pd.DataFrame(np.zeros([11,35]),columns=['NameList']+ChosenElem)\n",
    "PredLower['NameList']=snname\n",
    "for j in snname:\n",
    "    for k in ChosenElem:\n",
    "        lowerlimit,mid,upperlimit=OneSigmaCalculator(Yout=np.load('DataCache/2019.3.3/Yout'+k+'.npy'),Yreal=Y_test[k],center=np.array(PredData.loc[PredData['NameList']==j,k])[0],window=0.02)\n",
    "        PredUpper.loc[PredUpper['NameList']==j,k]=upperlimit\n",
    "        PredMid.loc[PredMid['NameList']==j,k]=mid\n",
    "        PredLower.loc[PredLower['NameList']==j,k]=lowerlimit\n",
    "RefineData,RefineUpper,RefineMid,RefineLower=PredData.copy(),PredUpper.copy(),PredMid.copy(),PredLower.copy()\n",
    "for j in snname:\n",
    "    for k in ChosenElem:\n",
    "        RefineData.loc[RefineData['NameList']==j,k]=Reverser(Yout=np.array(PredData.loc[PredData['NameList']==j,k])[0],elem=k)\n",
    "        RefineUpper.loc[RefineUpper['NameList']==j,k]=Reverser(Yout=np.array(PredUpper.loc[PredUpper['NameList']==j,k])[0],elem=k)\n",
    "        RefineMid.loc[RefineMid['NameList']==j,k]=Reverser(Yout=np.array(PredUpper.loc[PredUpper['NameList']==j,k])[0],elem=k)\n",
    "        RefineLower.loc[RefineLower['NameList']==j,k]=Reverser(Yout=np.array(PredLower.loc[PredUpper['NameList']==j,k])[0],elem=k)\n",
    "RefineData.to_csv('DataCache/2019.3.3/RefineData.csv')\n",
    "RefineUpper.to_csv('DataCache/2019.3.3/RefineUpper.csv')\n",
    "RefineMid.to_csv('DataCache/2019.3.3/RefineMid.csv')\n",
    "RefineLower.to_csv('DataCache/2019.3.3/RefineLower.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Element Solar Mass\n",
    "Because I am using a IG model as the base and discussing the multiplicaiton factors during deep learning, now I can simply convert the multiplicaiton factor to the real mass in the unit of mass of sun.  \n",
    "I firstly calculate the mass of each element in each zone in the IG model, then multiply the \"multiplicaiton factor\" onto it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_mass=1.98847*10**33#gram\n",
    "dens=np.genfromtxt('IGmodel/Density.dat',skip_header=1)\n",
    "mdd116=np.genfromtxt('IGmodel/Element.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ElemCal(Abundance,Density,VpH=7100,date=11.57,elem='26_3'):#to some reason the date seems useless. \n",
    "    ElemDens=Abundance[:,int(elem.split('_')[0])]*Density[:,2]\n",
    "    zone=int(elem.split('_')[1])\n",
    "    velogrid=0\n",
    "    if zone==1:velogrid=np.linspace(VpH,10000,num=200)\n",
    "    if zone==2:velogrid=np.linspace(10000,13200,num=200)\n",
    "    if zone==3:velogrid=np.linspace(13200,17000,num=200)\n",
    "    if zone==4:velogrid=np.linspace(17000,Density[:,1].max()-0.001,num=200)\n",
    "    ElemDensFunc=interp1d(Density[:,1],ElemDens)#This Element Density is the density at 11.57 days. According to the homogenity when ejecta is expanding, we add a time**-3 part below. \n",
    "    radius=date*24*3600*velogrid*100000 #In centimeter\n",
    "    ShellThickness=(velogrid[1]-velogrid[0])*date*24*3600*100000 # In centimeter\n",
    "    Mass=np.sum(ElemDensFunc(velogrid)*(11.57/date)**3*4*np.pi*(radius)**2*ShellThickness)\n",
    "    return Mass/solar_mass #in the unit of solar mass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate And Store\n",
    "I store the mass of different elements in different zones into the \"DataProduct\" directory.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "MassData=pd.DataFrame(np.zeros([11,35]),columns=['NameList']+ChosenElem)\n",
    "MassData['NameList']=snname\n",
    "MassUpper=pd.DataFrame(np.zeros([11,35]),columns=['NameList']+ChosenElem)\n",
    "MassUpper['NameList']=snname\n",
    "MassMid=pd.DataFrame(np.zeros([11,35]),columns=['NameList']+ChosenElem)\n",
    "MassMid['NameList']=snname\n",
    "MassLower=pd.DataFrame(np.zeros([11,35]),columns=['NameList']+ChosenElem)\n",
    "MassLower['NameList']=snname\n",
    "for j in snname:\n",
    "    for k in ChosenElem:\n",
    "        MassData.loc[MassData['NameList']==j,k]=PredData.loc[PredData['NameList']==j,k]*ElemCal(Abundance=mdd116,Density=dens,date=19,elem=k)  \n",
    "        MassUpper.loc[MassUpper['NameList']==j,k]=PredUpper.loc[PredUpper['NameList']==j,k]*ElemCal(Abundance=mdd116,Density=dens,date=19,elem=k)  \n",
    "        MassMid.loc[MassMid['NameList']==j,k]=PredMid.loc[PredMid['NameList']==j,k]*ElemCal(Abundance=mdd116,Density=dens,date=19,elem=k)  \n",
    "        MassLower.loc[MassLower['NameList']==j,k]=PredLower.loc[PredLower['NameList']==j,k]*ElemCal(Abundance=mdd116,Density=dens,date=19,elem=k)\n",
    "MassData.to_csv('DataProduct/2019.3.3/MassData.csv')\n",
    "MassLower.to_csv('DataProduct/2019.3.3/MassLower.csv')\n",
    "MassMid.to_csv('DataProduct/2019.3.3/MassMid.csv')\n",
    "MassUpper.to_csv('DataProduct/2019.3.3/MassUpper.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:keras]",
   "language": "python",
   "name": "conda-env-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
